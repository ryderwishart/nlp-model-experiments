{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryderwishart/nlp-model-experiments/blob/main/Greek_BERT_one_word_ln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "MDRy38oCHLPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment if you want to quickly delete unwanted files from previous model training\n",
        "import shutil\n",
        "#shutil.rmtree('/content/MyDrive/MyDrive/output')"
      ],
      "metadata": {
        "id": "m_r1VzNJGt8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow the general approach in this POS-tagging notebook: https://github.com/Kyubyong/nlp_made_easy/blob/master/Pos-tagging%20with%20Bert%20Fine-tuning.ipynb"
      ],
      "metadata": {
        "id": "5C9THvU4DcYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETNWnns13guq",
        "outputId": "cdc2c283-8536-42a5-f1e9-894f1eb5e499"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oh02vBxxLS4J"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'macula-greek.tsv' not in [path for path in os.listdir()]:\n",
        "    !wget -q 'https://raw.githubusercontent.com/Clear-Bible/macula-greek/main/Nestle1904/TSV/macula-greek.tsv'\n",
        "if 'ln_int_dict.txt' not in [path for path in os.listdir()]:\n",
        "    !wget -q 'https://raw.githubusercontent.com/ryderwishart/nlp-model-experiments/main/data/ln_int_dict.txt'\n",
        "if 'lemma_ln_dict.txt' not in [path for path in os.listdir()]:\n",
        "    !wget -q 'https://raw.githubusercontent.com/ryderwishart/nlp-model-experiments/main/data/lemma_ln_dict.txt'\n",
        "if 'ln_pos_dict.txt' not in [path for path in os.listdir()]:\n",
        "    !wget -q 'https://raw.githubusercontent.com/ryderwishart/nlp-model-experiments/main/data/ln_pos_dict.txt'"
      ],
      "metadata": {
        "id": "vNKiJ9yw8prd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load in data and dictionaries"
      ],
      "metadata": {
        "id": "lr0s8tG5AffU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data ='macula-greek.tsv'\n",
        "ln_int_dict = 'ln_int_dict.txt'\n",
        "lemma_ln_dict = 'lemma_ln_dict.txt'\n",
        "ln_pos_dict = 'ln_pos_dict.txt'"
      ],
      "metadata": {
        "id": "W9pdaGrfAexs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "4ExpE_X8BMUd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(ln_int_dict) as f:\n",
        "    ln_int_dict = json.load(f)\n",
        "\n",
        "with open(lemma_ln_dict, encoding=\"utf8\") as f:\n",
        "    lemma_ln_dict = json.load(f)\n",
        "\n",
        "with open(ln_pos_dict) as f:\n",
        "    ln_pos_dict = json.load(f)"
      ],
      "metadata": {
        "id": "U87KaTM7ByJk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# previous input factors: text, lemma\n",
        "input = 'text'\n",
        "# previous output factors: ln, type, role, pos\n",
        "output = 'ln'"
      ],
      "metadata": {
        "id": "WhkOZLSO1uJ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(data, sep='\\t', keep_default_na=False, encoding='utf-8')\n",
        "data = data[[input,output]]\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9jFyprS_BP0A",
        "outputId": "bbc99f5b-36ed-4730-d50e-5fb3e2ffe925"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       text           ln\n",
              "0    Βίβλος        33.38\n",
              "1  γενέσεως  10.24 33.19\n",
              "2     Ἰησοῦ      93.169a\n",
              "3   Χριστοῦ       93.387\n",
              "4      υἱοῦ        10.30"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3aebb88-8472-438b-ad40-26937435e7bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ln</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Βίβλος</td>\n",
              "      <td>33.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>γενέσεως</td>\n",
              "      <td>10.24 33.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ἰησοῦ</td>\n",
              "      <td>93.169a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Χριστοῦ</td>\n",
              "      <td>93.387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>υἱοῦ</td>\n",
              "      <td>10.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3aebb88-8472-438b-ad40-26937435e7bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3aebb88-8472-438b-ad40-26937435e7bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3aebb88-8472-438b-ad40-26937435e7bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lns = data['ln'].tolist()\n",
        "\n",
        "for i in range(len(lns)):\n",
        "  lns[i] = ln_int_dict[lns[i]]\n",
        "\n",
        "data = data.drop('ln', axis=1)\n",
        "data['ln'] = lns\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Jf7nBoxSx620",
        "outputId": "f5bc1454-5695-421a-e3a3-96970eaa186e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       text  ln\n",
              "0    Βίβλος   0\n",
              "1  γενέσεως   1\n",
              "2     Ἰησοῦ   2\n",
              "3   Χριστοῦ   3\n",
              "4      υἱοῦ   4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c883ada-5f35-40e8-a69b-4a81acd9cfcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ln</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Βίβλος</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>γενέσεως</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ἰησοῦ</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Χριστοῦ</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>υἱοῦ</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c883ada-5f35-40e8-a69b-4a81acd9cfcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c883ada-5f35-40e8-a69b-4a81acd9cfcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c883ada-5f35-40e8-a69b-4a81acd9cfcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick stats"
      ],
      "metadata": {
        "id": "dD0_qfOX6YKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = data['text'].nunique()\n",
        "print(f'{n_words} unique lemma forms are present')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOBNlnjVN6If",
        "outputId": "7e0ec8e9-6a5b-4db7-fe61-9b34bb24a391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19477 unique lemma forms are present\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem_doms = data['ln'].nunique()\n",
        "print(f'{sem_doms} unique semantic domains present')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKTGn4lWOF44",
        "outputId": "2e7a115a-cd45-4aa8-b40d-6dbd48ff079f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7815 unique semantic domains present\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hB_k7aMe7mG",
        "outputId": "c53f98da-b3d4-46bc-99d9-897422b9066f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137779"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT MODEL"
      ],
      "metadata": {
        "id": "nMu4OK2s6JgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "other models tested include: \n",
        "nlpaueb/bert-base-greek-uncased-v1, \n",
        "pranaydeeps/Ancient-Greek-BERT, \n",
        "bert-base-multilingual-cased, \n",
        "bert-base-multilingual-uncased\n",
        "'''\n",
        "pretrained = \"pranaydeeps/Ancient-Greek-BERT\""
      ],
      "metadata": {
        "id": "rtq6_PPZD2_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(pretrained)\n",
        "model = BertForSequenceClassification.from_pretrained(pretrained,\n",
        "                                                      num_labels = sem_doms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW31bGa-6dnh",
        "outputId": "5928a859-0553-409c-cbdd-aaf706de2783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pranaydeeps/Ancient-Greek-BERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to('cuda')"
      ],
      "metadata": {
        "id": "nqfp8ifR6jCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def strip_accents_and_lowercase(s):\n",
        "#   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "#                  if unicodedata.category(c) != 'Mn').lower()"
      ],
      "metadata": {
        "id": "45FyPRR0x7W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test a sample sentence to see if everything is working as it should\n",
        "#sample_data = ['ἀρχὴ τοῦ εὐαγγελίου Ἰησοῦ Χριστοῦ υἱοῦ θεοῦ.']\n",
        "#for sentence in range(len(sample_data)):\n",
        "#  clean = strip_accents_and_lowercase(sample_data[sentence])\n",
        "#  sample_data[sentence] = clean\n",
        "#tokenizer(sample_data, padding = True, truncation = True, max_length = 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grI8Djlh7df4",
        "outputId": "9d36c7cc-0d6d-4a17-cf2d-15bc317bdf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 664, 346, 23115, 4326, 2371, 17006, 1210, 121, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing what various tokens are\n",
        "#tokenizer.convert_ids_to_tokens(664)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yf1sjLdg7szO",
        "outputId": "85db46a5-a9ad-487b-f6f7-f77d56cbafcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'αρχη'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(data['text'])\n",
        "y = list(data['ln'])\n",
        "# 70/20/10 split for train, val, and test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2) # 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.125) # 70/10\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "CRtuq2Yit0Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{len(X_train)} items in the training set.')\n",
        "print(f'{len(X_val)} items in the validation set.')\n",
        "print(f'{len(X_test)} items in the test set.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6-sNRSqgN3b",
        "outputId": "47ee92e9-0111-4c46-ac7d-4dd397fa0a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96445 items in the training set.\n",
            "27556 items in the validation set.\n",
            "13778 items in the test set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Create dataset\n",
        " class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n"
      ],
      "metadata": {
        "id": "nrf6vlXBuj98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "id": "S7ybHh3rvom-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred, average='weighted')\n",
        "    precision = precision_score(y_true=labels, y_pred=pred, average='weighted')\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "IY_BQe5swGzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    # Change if you want the checkpoints to go somewhere else\n",
        "    output_dir=\"/content/MyDrive/MyDrive/output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    per_device_train_batch_size=2048,\n",
        "    per_device_eval_batch_size=2048,\n",
        "    num_train_epochs=10,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3G3q3KLqwVdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "o97gb295w5Z9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "703c5334-e763-4335-9354-1d3fe4c53f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1920' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1920/1920 25:52, Epoch 40/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.283328</td>\n",
              "      <td>0.372587</td>\n",
              "      <td>0.209530</td>\n",
              "      <td>0.372587</td>\n",
              "      <td>0.257747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.235488</td>\n",
              "      <td>0.495065</td>\n",
              "      <td>0.345954</td>\n",
              "      <td>0.495065</td>\n",
              "      <td>0.390494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.709043</td>\n",
              "      <td>0.558535</td>\n",
              "      <td>0.420499</td>\n",
              "      <td>0.558535</td>\n",
              "      <td>0.460937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.390668</td>\n",
              "      <td>0.588692</td>\n",
              "      <td>0.464412</td>\n",
              "      <td>0.588692</td>\n",
              "      <td>0.497510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.466700</td>\n",
              "      <td>2.176357</td>\n",
              "      <td>0.612026</td>\n",
              "      <td>0.497292</td>\n",
              "      <td>0.612026</td>\n",
              "      <td>0.525919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.466700</td>\n",
              "      <td>2.026451</td>\n",
              "      <td>0.627123</td>\n",
              "      <td>0.520664</td>\n",
              "      <td>0.627123</td>\n",
              "      <td>0.544055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.466700</td>\n",
              "      <td>1.917531</td>\n",
              "      <td>0.632167</td>\n",
              "      <td>0.523542</td>\n",
              "      <td>0.632167</td>\n",
              "      <td>0.557657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.466700</td>\n",
              "      <td>1.834535</td>\n",
              "      <td>0.638482</td>\n",
              "      <td>0.531619</td>\n",
              "      <td>0.638482</td>\n",
              "      <td>0.566418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.466700</td>\n",
              "      <td>1.770055</td>\n",
              "      <td>0.647990</td>\n",
              "      <td>0.551958</td>\n",
              "      <td>0.647990</td>\n",
              "      <td>0.573305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.741200</td>\n",
              "      <td>1.717357</td>\n",
              "      <td>0.649223</td>\n",
              "      <td>0.550897</td>\n",
              "      <td>0.649223</td>\n",
              "      <td>0.580232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.741200</td>\n",
              "      <td>1.679394</td>\n",
              "      <td>0.653868</td>\n",
              "      <td>0.563757</td>\n",
              "      <td>0.653868</td>\n",
              "      <td>0.581916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.741200</td>\n",
              "      <td>1.644410</td>\n",
              "      <td>0.658260</td>\n",
              "      <td>0.570890</td>\n",
              "      <td>0.658260</td>\n",
              "      <td>0.586350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.741200</td>\n",
              "      <td>1.620555</td>\n",
              "      <td>0.659965</td>\n",
              "      <td>0.575307</td>\n",
              "      <td>0.659965</td>\n",
              "      <td>0.591515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.741200</td>\n",
              "      <td>1.602148</td>\n",
              "      <td>0.660473</td>\n",
              "      <td>0.573089</td>\n",
              "      <td>0.660473</td>\n",
              "      <td>0.593869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.402200</td>\n",
              "      <td>1.586602</td>\n",
              "      <td>0.660945</td>\n",
              "      <td>0.573241</td>\n",
              "      <td>0.660945</td>\n",
              "      <td>0.591567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.402200</td>\n",
              "      <td>1.574960</td>\n",
              "      <td>0.663195</td>\n",
              "      <td>0.576545</td>\n",
              "      <td>0.663195</td>\n",
              "      <td>0.597391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.402200</td>\n",
              "      <td>1.566225</td>\n",
              "      <td>0.664538</td>\n",
              "      <td>0.579305</td>\n",
              "      <td>0.664538</td>\n",
              "      <td>0.596263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.402200</td>\n",
              "      <td>1.561546</td>\n",
              "      <td>0.664175</td>\n",
              "      <td>0.578685</td>\n",
              "      <td>0.664175</td>\n",
              "      <td>0.595770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.402200</td>\n",
              "      <td>1.559391</td>\n",
              "      <td>0.664755</td>\n",
              "      <td>0.580111</td>\n",
              "      <td>0.664755</td>\n",
              "      <td>0.596715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1920, training_loss=2.004433250427246, metrics={'train_runtime': 1554.5678, 'train_samples_per_second': 2481.59, 'train_steps_per_second': 1.235, 'total_flos': 2.1215506698036e+16, 'train_loss': 2.004433250427246, 'epoch': 40.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST"
      ],
      "metadata": {
        "id": "Yuige6FLL6-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:5]"
      ],
      "metadata": {
        "id": "LtZ0ECWPdxmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true values\n",
        "y_test[:5]"
      ],
      "metadata": {
        "id": "KCW8Yp_elOih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "test_dataset = Dataset(X_test_tokenized)"
      ],
      "metadata": {
        "id": "7k7ePWOPm833"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE MODEL PATH TO BEST PERFORMING MODEL\n",
        "model_path = \"/content/output/checkpoint-500\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=sem_doms, ignore_mismatched_sizes=True)"
      ],
      "metadata": {
        "id": "2pdnl1rlm-cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_trainer = Trainer(model)"
      ],
      "metadata": {
        "id": "qwFtUAcAnILG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pred, _, _ = test_trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "bHL0hP5OnKGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(raw_pred, axis=1)"
      ],
      "metadata": {
        "id": "JYwo11aDnL8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = y_pred.tolist()"
      ],
      "metadata": {
        "id": "w2wJWwbKtrn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[:5]"
      ],
      "metadata": {
        "id": "DxDk_xLhuQPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Up Data into Groups"
      ],
      "metadata": {
        "id": "UdsnNTMvBX4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze performance between content words (common nouns, proper nouns, adjectives, verbs, adverbs) and function words (i.e. conjunctions and prepositions)\n"
      ],
      "metadata": {
        "id": "EFRes49YMlM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = []\n",
        "function = []\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  a = int_ln_dict[str(y_test[i])]\n",
        "  b = int_ln_dict[str(predictions[i])]\n",
        "  if ln_pos_dict[a] in ('common noun', 'proper noun', 'adjective', 'verb'):\n",
        "    content.append(tuple((a, b)))\n",
        "  else:\n",
        "    function.append(tuple((a, b)))"
      ],
      "metadata": {
        "id": "ZgIlOHQqNjlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze performance between words seen in the training dataset and those only seen in the test dataset"
      ],
      "metadata": {
        "id": "8xnuj9CeZdBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_train = []\n",
        "out_train = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  a = int_ln_dict[str(y_test[i])]\n",
        "  b = int_ln_dict[str(predictions[i])]\n",
        "  if (y_test[i] in y_train) or (y_test[i] in y_val):\n",
        "    in_train.append(tuple((a, b)))\n",
        "  else:\n",
        "    out_train.append(tuple((a, b)))"
      ],
      "metadata": {
        "id": "-FgiX9cfZqBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adverbs make my brain hurt, so they're just going to be \"function\" words\n",
        "pos_list = ['common noun', 'proper noun', 'adjective', 'verb', 'adverb', \n",
        "            'determiner', 'conjunction', 'preposition',\n",
        "              'pronoun', 'particle', 'number', 'interjection']"
      ],
      "metadata": {
        "id": "E-kQ_lcH2RYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze performance between ambiguous (lemma occurs with multiple ln domains) and unambiguous (lemma occurs with single ln domain) words"
      ],
      "metadata": {
        "id": "bjSndcKELRD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ambiguous_ln = []\n",
        "ambiguous_words = []\n",
        "unambiguous_ln = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  a = int_ln_dict[str(y_test[i])]\n",
        "  b = int_ln_dict[str(predictions[i])]\n",
        "  domains = lemma_ln_dict[X_test[i]]\n",
        "  if len(domains) > 1:\n",
        "    ambiguous_ln.append(tuple((a, b)))\n",
        "    ambiguous_words.append(X_test[i])\n",
        "  else:\n",
        "    unambiguous_ln.append(tuple((a, b)))"
      ],
      "metadata": {
        "id": "56pvJOUfLaNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "MUo2gQxaiySk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_incorrect_lists(set_list: list) -> list:\n",
        "  incorrect_list = []\n",
        "\n",
        "  for i in set_list:\n",
        "    if i[0] != i[1]:\n",
        "      incorrect_list.append(i)\n",
        "\n",
        "  return incorrect_list"
      ],
      "metadata": {
        "id": "v_zkfBeeix47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_incorrect_ambiguity_list(set_list: list, ambiguous_words: list) -> list:\n",
        "  incorrect_list = []\n",
        "  corresponding_domains = []\n",
        "\n",
        "  for i in range(len(set_list)):\n",
        "    if set_list[i][0] != set_list[i][1]:\n",
        "      incorrect_list.append(set_list[i])\n",
        "      corresponding_domains.append(lemma_ln_dict[ambiguous_words[i]])\n",
        "\n",
        "  return incorrect_list, corresponding_domains"
      ],
      "metadata": {
        "id": "S-0hFFWJUtUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_all_wrong(wrong_list: list, total: list):\n",
        "  wrong_count = len(wrong_list)\n",
        "  all_count = len(total)\n",
        "  accuracy = wrong_count/all_count\n",
        "\n",
        "  print(f'{wrong_count} domains incorrectly identified out of {all_count}.')\n",
        "  print(f'{round(accuracy, 4)*100}% of domains incorrectly identified')"
      ],
      "metadata": {
        "id": "XUJNMuMskyKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_wrong_ln_by_pos(pos_list: list, wrong_list: list) -> dict:\n",
        "  key_list = pos_list\n",
        "  wrong_pos_counts = {k:0 for k in key_list}\n",
        "  \n",
        "  for i in wrong_list:\n",
        "    pos = ln_pos_dict[i[0][0]]\n",
        "    wrong_pos_counts[pos] += i[1]\n",
        "  \n",
        "  return wrong_pos_counts"
      ],
      "metadata": {
        "id": "4B4jIBTbnKbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_all_pos(pos_list: list, set_list: list) -> dict:\n",
        "  key_list = pos_list\n",
        "  all_pos_counts = {k:0 for k in key_list}\n",
        "\n",
        "  try:\n",
        "    for i in set_list:\n",
        "      all_pos_counts[ln_pos_dict[i[0]]] += 1\n",
        "  except:\n",
        "    for i in set_list:\n",
        "      all_pos_counts[ln_pos_dict[int_ln_dict[str(i)]]] += 1\n",
        "    \n",
        "  return all_pos_counts"
      ],
      "metadata": {
        "id": "5dMFdp5cnnAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pos_stats(wrong_pos_counts: dict, all_pos_counts: dict) -> list:   \n",
        "  stats = []\n",
        "  for i in wrong_pos_counts:\n",
        "    if all_pos_counts[i] == 0:\n",
        "          stats.append('{} out of {} {}s incorrect (0.0)'\n",
        "              .format(wrong_pos_counts[i], all_pos_counts[i], i))\n",
        "    else:\n",
        "        stats.append('{} out of {} {}s incorrect ({})'\n",
        "              .format(wrong_pos_counts[i], all_pos_counts[i], i, \n",
        "                      round((wrong_pos_counts[i]/all_pos_counts[i]), 4)))\n",
        "\n",
        "  return stats"
      ],
      "metadata": {
        "id": "VxNRlr_Emuka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_relevant_stats(pos_type: str, stats: list):\n",
        "  pos_type = pos_type.lower()\n",
        "  # if pos_list changes, adjust where list is split\n",
        "  pos_dict = {\n",
        "      'content': stats[:4],\n",
        "      'function': stats[4:],\n",
        "      'both': stats\n",
        "  }\n",
        "\n",
        "  if pos_type in pos_dict:\n",
        "    for i in pos_dict[pos_type]:\n",
        "      print(i)\n",
        "  else:\n",
        "    print('Please enter \"content\", \"function\", or \"both\" for pos_type.')"
      ],
      "metadata": {
        "id": "QRGAmvwp0Xtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Content word analysis"
      ],
      "metadata": {
        "id": "9udULlg3PQuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_content = generate_incorrect_lists(content)\n",
        "incorrect_content[:5]"
      ],
      "metadata": {
        "id": "CcYYeyYfPtAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_all_wrong(incorrect_content, content)"
      ],
      "metadata": {
        "id": "OG4gZJqQ5VTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_counts = Counter(incorrect_content).most_common()\n",
        "cont_counts[:5]"
      ],
      "metadata": {
        "id": "4omiJcsoQHZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_wrong = count_wrong_ln_by_pos(pos_list, cont_counts)\n",
        "cont_all = count_all_pos(pos_list, y_test)\n",
        "cont_stats = create_pos_stats(cont_wrong, cont_all)\n",
        "return_relevant_stats('content', cont_stats)"
      ],
      "metadata": {
        "id": "pZZ05CS-pdCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function Word Analysis"
      ],
      "metadata": {
        "id": "EuPy2Ce6Pm-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_function = generate_incorrect_lists(function)\n",
        "incorrect_function[:5]"
      ],
      "metadata": {
        "id": "HHEzSpRaLTMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_all_wrong(incorrect_function, function)"
      ],
      "metadata": {
        "id": "Wq3au6OqLTWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_counts = Counter(incorrect_function).most_common()\n",
        "func_counts[:5]"
      ],
      "metadata": {
        "id": "GC-JycnHMAbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_wrong = count_wrong_ln_by_pos(pos_list, func_counts)\n",
        "func_all = count_all_pos(pos_list, y_test)\n",
        "func_stats = create_pos_stats(func_wrong, func_all)\n",
        "return_relevant_stats('function', func_stats)"
      ],
      "metadata": {
        "id": "JuPGMlXyqXKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In Training Analysis"
      ],
      "metadata": {
        "id": "P91JIYUKZR_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_train[:5]"
      ],
      "metadata": {
        "id": "IcRUR2bJZX2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_in = generate_incorrect_lists(in_train)\n",
        "count_all_wrong(incorrect_in, in_train)"
      ],
      "metadata": {
        "id": "yQVyf0Lxa59S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_counts = Counter(incorrect_in).most_common()\n",
        "in_counts[:5]"
      ],
      "metadata": {
        "id": "EUSem3ltcuq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_wrong = count_wrong_ln_by_pos(pos_list, in_counts)\n",
        "in_all = count_all_pos(pos_list, in_train)\n",
        "in_stats = create_pos_stats(in_wrong, in_all)\n",
        "return_relevant_stats('both', in_stats)"
      ],
      "metadata": {
        "id": "xhWyhUrbqr6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Out Of Training Analysis"
      ],
      "metadata": {
        "id": "1f-3Wa6Db9Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_train[:5]"
      ],
      "metadata": {
        "id": "WEsIhO3vb_3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_out = generate_incorrect_lists(out_train)\n",
        "count_all_wrong(incorrect_out, out_train)"
      ],
      "metadata": {
        "id": "7n_yXIdtcPvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_counts = Counter(incorrect_out).most_common()\n",
        "out_counts[:5]"
      ],
      "metadata": {
        "id": "Qwaptt50gc5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_wrong = count_wrong_ln_by_pos(pos_list, out_counts)\n",
        "out_all = count_all_pos(pos_list, out_train)\n",
        "out_stats = create_pos_stats(out_wrong, out_all)\n",
        "return_relevant_stats('both', out_stats)"
      ],
      "metadata": {
        "id": "Z5am7cTSeq0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ambiguous Words"
      ],
      "metadata": {
        "id": "xtW8q3wUKPe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ambiguous_ln[:5]"
      ],
      "metadata": {
        "id": "Hez7U5q2KSVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_amb, amb_ln = generate_incorrect_ambiguity_list(ambiguous_ln, ambiguous_words)\n",
        "count_all_wrong(incorrect_amb, ambiguous_ln)"
      ],
      "metadata": {
        "id": "ZyEZH5CbKVY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amb_counts = Counter(incorrect_amb).most_common()\n",
        "amb_counts[:5]"
      ],
      "metadata": {
        "id": "PseLpoPdKfQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amb_wrong = count_wrong_ln_by_pos(pos_list, amb_counts)\n",
        "amb_all = count_all_pos(pos_list, ambiguous_ln)\n",
        "amb_stats = create_pos_stats(amb_wrong, amb_all)\n",
        "return_relevant_stats('both', amb_stats)"
      ],
      "metadata": {
        "id": "M2sIxlg2KmDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the instances of these ln domains and see if the model is simply guessing the most common domain for these ambigous words."
      ],
      "metadata": {
        "id": "Ii94w7bUY64W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_counts = 0\n",
        "not_common_counts = 0\n",
        "for i in amb_counts:\n",
        "  j = incorrect_amb.index(i[0])\n",
        "  current_dict = amb_ln[j]\n",
        "  most_common = max(current_dict, key = current_dict.get)\n",
        "  if most_common == i[0][1]:\n",
        "    common_counts += i[1]\n",
        "  else:\n",
        "    not_common_counts += i[1]\n",
        "\n",
        "print(f'model incorrectly guessed the most common domain {common_counts} times')\n",
        "print(f'model incorrectly guessed something besides the most common domain {not_common_counts} times')"
      ],
      "metadata": {
        "id": "iqWHdhuZX_g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unambiguous Words"
      ],
      "metadata": {
        "id": "PO_QngK0K1UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unambiguous_ln[:5]"
      ],
      "metadata": {
        "id": "Oe32QoYVK3rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_unamb = generate_incorrect_lists(unambiguous_ln)\n",
        "count_all_wrong(incorrect_unamb, unambiguous_ln)"
      ],
      "metadata": {
        "id": "DzuoXGzuK3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unamb_counts = Counter(incorrect_unamb).most_common()\n",
        "unamb_counts[:5]"
      ],
      "metadata": {
        "id": "H718t5h7K31Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unamb_wrong = count_wrong_ln_by_pos(pos_list, unamb_counts)\n",
        "unamb_all = count_all_pos(pos_list, unambiguous_ln)\n",
        "unamb_stats = create_pos_stats(unamb_wrong, unamb_all)\n",
        "return_relevant_stats('both', unamb_stats)"
      ],
      "metadata": {
        "id": "aCoV2D8CK354"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unfiltered Test Analsis"
      ],
      "metadata": {
        "id": "f7E4QTdFOLEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mismatches = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] != predictions[i]:\n",
        "    a = int_ln_dict[str(y_test[i])]\n",
        "    b = int_ln_dict[str(predictions[i])]\n",
        "    mismatches.append(tuple((a, b)))\n",
        "\n",
        "mismatches[:5]"
      ],
      "metadata": {
        "id": "mwahYnhtu64r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_wrong = generate_incorrect_lists(mismatches)\n",
        "count_all_wrong(all_wrong, y_test)"
      ],
      "metadata": {
        "id": "eJr6znot-s0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_counts = Counter(mismatches).most_common()\n",
        "all_counts[:5]"
      ],
      "metadata": {
        "id": "55G2Lk21xpbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_counts = count_wrong_ln_by_pos(pos_list, all_counts)\n",
        "all_counts = count_all_pos(pos_list, y_test)\n",
        "all_stats = create_pos_stats(wrong_counts, all_counts)\n",
        "return_relevant_stats('both', all_stats)"
      ],
      "metadata": {
        "id": "v6wA9sa8t4Wp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}